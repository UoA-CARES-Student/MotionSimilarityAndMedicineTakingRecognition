{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Run.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1G9vsSWwlO7aQb0fdFw0Yhl9xsRYStaZi","authorship_tag":"ABX9TyN5y+kAHPaUogbHrt304UgI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PXHaVR82-7jb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","cd '/content/drive/Shareddrives/Part IV Research Project/Medicine Action'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cv2znzqk1P8A"},"source":["import numpy as np\n","import cv2, re, os, keras, warnings, time\n","from keras.models import Model\n","import keras.layers as L\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.optimizers import RMSprop\n","from keras import models\n","#from keras import optimizers\n","from tensorflow.keras.applications import VGG16\n","from google.colab.patches import cv2_imshow\n","\n","\n","#from Mailer import Mailer\n","import Mailer\n","#from Config import Config\n","import Config as config\n","warnings.filterwarnings('ignore')\n","\n","CAM_CONSTANT = 0\n","\n","# CNN VGG model\n","class FeatExtractor:\n","    def __init__(self, SIZE):\n","        self.size = config.SIZE\n","        self.vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(self.size[0], self.size[1], 3))\n","        for layer in self.vgg_conv.layers[:-4]:\n","            layer.trainable = False\n","\n","        # Create the model\n","        def build_feat_extractor():\n","            model = models.Sequential()\n","\n","            # Add the vgg convolutional base model\n","            model.add(self.vgg_conv)\n","\n","            # Add new layers\n","            model.add(L.Flatten())\n","            model.add(L.Dense(1024, activation='relu'))\n","            model.add(L.Dropout(0.2))\n","            model.add(L.Dense(256, activation='relu'))\n","            model.add(L.Dense(2, activation='softmax'))\n","            return model\n","\n","        self.model = build_feat_extractor()\n","        self.model.compile(loss='categorical_crossentropy',\n","                      optimizer=optimizers.RMSprop(lr=1e-4),\n","                      metrics=['acc'])\n","\n","        self.model.load_weights('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/weights/Feature_Extractor.h5')\n","\n","        inp = self.model.input\n","        out = self.model.layers[-4].output\n","        self.model = Model(inputs=[inp], outputs=[out])\n","\n","        self.model.compile(loss='categorical_crossentropy',\n","                      optimizer=optimizers.RMSprop(lr=1e-4),\n","                      metrics=['acc'])\n","\n","    def get_feats(self, frames):\n","        image_data = np.zeros((len(frames), config.VGG16_OUT))\n","        for index, image in enumerate(frames):\n","            vect = self.model.predict(image.reshape(1, self.size[0], self.size[1], 3))\n","            image_data[index, :] = vect\n","\n","        image_data = image_data.reshape(1, len(frames), config.VGG16_OUT)\n","        return image_data\n","\n","# RNN model\n","class RnnModel:\n","\n","    def __init__(self, NUM_FEATURES, LOOK_BACK):\n","        self.num_features = NUM_FEATURES\n","        self.look_back = config.LOOK_BACK\n","        def build_model():\n","            inp = L.Input(shape=(self.look_back, self.num_features))\n","            x = L.LSTM(64, return_sequences=True)(inp)\n","            x = L.Dropout(0.2)(x)\n","            x = L.LSTM(16)(x)\n","\n","            out = L.Dense(2, activation='softmax')(x)\n","            model = Model(inputs=[inp], outputs=[out])\n","            model.compile(loss='categorical_crossentropy',\n","                          optimizer=RMSprop(lr=1e-4),\n","                          metrics=['acc'])\n","            return model\n","\n","        self.model = build_model()\n","        self.model.load_weights('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/weights/RNN.h5')\n","\n","    def predict(self, frame_data):\n","        pred = self.model.predict(frame_data)\n","        self.model.save('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/weights/VGG.h5')\n","        return pred[0][1]\n","\n","def __draw_label(img, text, pos, bg_color):\n","    font_face = cv2.FONT_HERSHEY_SIMPLEX\n","    scale = 0.8\n","    color = (0, 0, 0)\n","    thickness = cv2.FILLED\n","    margin = 2\n","\n","    txt_size = cv2.getTextSize(text, font_face, scale, thickness)\n","\n","    end_x = pos[0] + txt_size[0][0] + margin\n","    end_y = pos[1] - txt_size[0][1] - margin\n","\n","    cv2.rectangle(img, pos, (end_x, end_y), bg_color, thickness)\n","    cv2.putText(img, text, pos, font_face, scale, color, 1, cv2.LINE_AA)\n","\n","#===============================================================================\n","# Initiate the main function\n","if __name__ == '__main__':\n","    if not config.FROM_WEBCAM:\n","        # Enter your desired test video path\n","        cap = cv2.VideoCapture('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/tests/DrinkingTest1.avi')\n","    else:\n","        # From webcam\n","        cap = cv2.VideoCapture(CAM_CONSTANT, cv2.CAP_DSHOW)\n","    \n","    cnt = 0\n","    frames = []\n","    fe = FeatExtractor(config.SIZE)\n","    rnn = RnnModel(config.VGG16_OUT, config.LOOK_BACK)\n","    total_frames = 0\n","    detect_certainty = []\n","    neg_certainty = []\n","    #output = cv2.VideoWriter('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/output.avi', -1, 20.0, (640,480))\n","    while (cap.isOpened()):\n","        #save the output video\n","        output = cv2.VideoWriter('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/output.avi', -1, 20.0, (640,480))\n","        # Capture frame-by-frame\n","        cnt+=1\n","        ret, full = cap.read()\n","        try:\n","          frame = cv2.resize(full, (224,224),fx=0,fy=0, interpolation = cv2.INTER_AREA)\n","        except:\n","          break\n","          \n","        if cnt % config.TAKE_FRAME == 0:\n","            frames.append(frame)\n","            pred = 0\n","            if len(frames) == config.LOOK_BACK:\n","                # Get features\n","                feats = fe.get_feats(frames)\n","                frames.pop(0)\n","                initial = time.time()\n","                pred = rnn.predict(feats)\n","                final = time.time() - initial\n","                print(\"\")\n","                # Check predictions per frame (either 0 or 1)\n","                print('[INFO] Frame acc. predictions:', pred*10)\n","                # Check inference time per frame\n","                print('Frame inference in %.4f seconds' % (final))\n","\n","            if ret == True:\n","                # Display the resulting frame\n","                # Optimize the threshold (avg. prediction score for class labels) if desired\n","                # 1 for class1 and 0 for class2. Please refer config.\n","                # threshold = 0.5\n","                #if pred >= config.Threshold:\n","                if pred >= 0.06:\n","                    __draw_label(full, 'Drinking', (20, 20), (255, 255, 255))\n","                    total_frames += 1\n","                    detect_certainty.append(pred)\n","                else:\n","                    neg_certainty.append(pred)\n","                    if config.ALERT:\n","                        # Adjust the total_frames (avg. score to send the mail). Refer config.\n","                        if total_frames > config.positive_frames:\n","                            print('[INFO] Sending mail...')\n","                            neg = np.mean(neg_certainty)\n","                            pos = np.mean(detect_certainty)\n","                            time1 = total_frames * config.TAKE_FRAME / 30\n","                            Mailer().send(config.MAIL, total_frames, time1, pos, neg)\n","                            print('[INFO] Mail sent')\n","                        detect_certainty = []\n","                        total_frames = 0\n","                    __draw_label(full, 'Taking medicine', (20, 20), (255, 255, 255))\n","                    output.write(full)\n","                #cv2.save('Test_Window',full)\n","                #cv2.imshow('Test_Window', full)\n","                cv2_imshow(full)\n","                \n","\n","                # Press Q on keyboard to exit\n","                if cv2.waitKey(25) & 0xFF == ord('q'):\n","                    break\n","                output.release()\n","            # Break the loop\n","            else:\n","                break\n","        #output.release()\n","    # When everything done, release the video capture object\n","    cap.release()\n","    #output.release()"],"execution_count":null,"outputs":[]}]}