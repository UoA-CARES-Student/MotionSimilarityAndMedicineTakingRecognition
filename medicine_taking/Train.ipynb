{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Train.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1nl2NEDRHsi7BOH8tzc0QUrYq6B6Bqu-8","authorship_tag":"ABX9TyPXwz7oERDwcjYtfpKIcpN5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"bNnYEwU4TXUO"},"source":["# To check whether GPU is available\n","from tensorflow.python.client import device_lib\n","from warnings import filterwarnings\n","filterwarnings('ignore')\n","\n","print(device_lib.list_local_devices()) # list of DeviceAttributes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HjY0XPGTZPu"},"source":["import tensorflow as tf\n","tf.test.is_gpu_available() # Returns true/False\n","\n","# Or only check for GPU's with CUDA support\n","tf.test.is_gpu_available(cuda_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8DOpxtsTcCd"},"source":["import pandas as pd\n","import numpy as np\n","import os, time, cv2, tqdm, datetime\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","from warnings import filterwarnings\n","filterwarnings('ignore')\n","\n","SIZE = (224,224)\n","#train path for each class\n","POSITIVES_PATH_TRAIN = '/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Train/Class1/'\n","NEGATIVES_PATH_TRAIN = '/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Train/Class2/'\n","\n","POSITIVES_PATH_VALID = '/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Val/Class1/'\n","NEGATIVES_PATH_VALID = '/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Val/Class2/'\n","\n","# POSITIVES_PATH_TEST = \n","# NEGATIVES_PATH_TEST ="],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EUvdQdRlTfRG"},"source":["from keras.applications.vgg16 import VGG16\n","\n","# Load the VGG model\n","vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE[0], SIZE[1], 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2VYthCt4Thlv"},"source":["# Freeze the layers except the last 4 layers\n","for layer in vgg_conv.layers[:-4]:\n","    layer.trainable = False\n","    \n","# labels enabled for fine-tuning    \n","for layer in vgg_conv.layers:\n","    print(layer, layer.trainable)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rft7MwTHTjpo"},"source":["from keras import models\n","from keras import layers\n","from keras import optimizers\n"," \n","# Create the VGG16 model\n","def build_feat_extractor():\n","    model = models.Sequential()\n","\n","    # Add the vgg convolutional base model\n","    model.add(vgg_conv)\n","\n","    # Add new layers\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1024, activation='relu'))\n","    model.add(layers.Dropout(0.2))\n","    model.add(layers.Dense(256, activation = 'relu'))\n","    model.add(layers.Dense(2, activation='softmax'))\n","    return model\n","\n","build_feat_extractor().summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2L3-k0MQTmaT"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_batchsize = 64\n","train_datagen = ImageDataGenerator(\n","      rescale=1./255,\n","      rotation_range=20,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","#data/Train\n","#/content/drive/MyDrive/Action Recognition/data\n","train_generator = train_datagen.flow_from_directory('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Train', class_mode='categorical', batch_size=train_batchsize, target_size = SIZE)\n","\n","val_datagen = ImageDataGenerator(\n","      rescale=1./255,\n","      rotation_range=20,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","val_generator = val_datagen.flow_from_directory('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Val/', class_mode='categorical', batch_size=train_batchsize, target_size = SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETIpv9RRTpBq"},"source":["# Compile the model\n","from keras.callbacks import TensorBoard\n","from tensorflow.keras import optimizers\n","\n","model = build_feat_extractor()\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['acc'])\n","\n","# Train the model\n","model.fit_generator(\n","      train_generator,  \n","      steps_per_epoch=train_generator.samples/train_generator.batch_size,\n","      validation_data = val_generator,\n","      validation_steps = val_generator.samples/val_generator.batch_size,\n","      epochs=10,\n","      verbose=2)\n"," \n","# Save the trained model to disk\n","model.save('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/weights/Feature_Extractor.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w2gO8jV2Trxu"},"source":["from keras.models import Model\n","import keras.layers as L\n","from tensorflow.keras import optimizers\n","\n","inp = model.input\n","out = model.layers[-4].output\n","feat_extractor = Model(inputs = [inp], outputs = [out])\n","feat_extractor.summary()\n","\n","feat_extractor.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8XVqwFXTtyL"},"source":["import re\n","import numpy as np\n","import os, time, cv2, tqdm, datetime\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","LOOK_BACK = 4\n","SIZE = (224,224)\n","POSITIVES_PATH_TRAIN = '/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Train/Class1/'\n","NEGATIVES_PATH_TRAIN = '/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Train/Class2/'\n","\n","POSITIVES_PATH_VALID = '/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Val/Class1/'\n","NEGATIVES_PATH_VALID = '/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/Val/Class2/'\n","\n","\n","def data_to_lstm_format(POSITIVES_PATH, NEGATIVES_PATH, look_back = 4):\n","    data = np.array([])\n","    labels = np.array([])\n","    numbers = []\n","    # POSITIVE LABELS\n","    for value in os.listdir(POSITIVES_PATH):\n","        numbers.append(int(re.findall(r'\\d+', value.split('_')[1])[0]))\n","    #except ValueError:\n","      #pass\n","        #print(\"Positive Part: \",int(re.findall(r'\\d+', value.split('_')[1])[0]))\n","\n","    # filter by video\n","    for numb in np.unique(numbers):\n","        frames = []\n","        # append image name\n","        for value in os.listdir(POSITIVES_PATH):\n","            if int(re.findall(r'\\d+', value.split('_')[1])[0]) == numb:\n","                frames.append(value)\n","        # sort image frame by frame number\n","        frames = sorted(frames, key = lambda x: int(re.findall(r'\\d+', x.split('_')[-1].split('.')[0])[0]))\n","        image_data = np.zeros((len(frames), 1024))\n","\n","        # get feature vector from vgg16 for each frame and stack\n","        for index, image in enumerate(frames):\n","            img = cv2.imread(POSITIVES_PATH + image)\n","            vect = feat_extractor.predict(img.reshape(1,224,224,3))\n","            image_data[index,:] = vect\n","\n","        # for each frame get tensor with lookbacks\n","        stacked_data = np.zeros((len(frames), look_back, 1024))\n","        for index in range(len(frames)):\n","            labels = np.append(labels, [1])\n","            stacked_data[index, 0, :] = image_data[index]\n","            for lb in range(1, look_back):\n","                if index - lb >= 0:\n","                    stacked_data[index, lb, :] = image_data[index - lb]\n","                else:\n","                    stacked_data[index, lb, :] = np.zeros(1024)\n","\n","        if data.shape[0] == 0:\n","            try:\n","              data = stacked_data\n","            except ValueError:\n","              pass\n","        else:\n","            try:\n","              data = np.concatenate([data, stacked_data], axis = 0)\n","            except ValueError:\n","              pass\n","\n","\n","\n","    for value in os.listdir(NEGATIVES_PATH):\n","        #numbers.append(int(re.findall(r'\\d+', value.split('_')[1])[0]))\n","        numbers.append(int(re.findall(r'\\d+', value.split('_')[0])[0]))\n","      #except ValueError:\n","        #pass\n","\n","    # filter by video\n","    for numb in np.unique(numbers):\n","        frames = []\n","        # append image name\n","        for value in os.listdir(NEGATIVES_PATH):\n","            #if int(re.findall(r'\\d+', value.split('_')[1])[0]) == numb:\n","            if int(re.findall(r'\\d+', value.split('_')[0])[0]) == numb:  \n","                frames.append(value)\n","                #print(\"Negative Part2 \",re.findall(r'\\d+', value.split('_')[0])[0])\n","        # sort image frame by frame number\n","        frames = sorted(frames, key = lambda x: int(re.findall(r'\\d+', x.split('_')[-1].split('.')[0])[0]))\n","        image_data = np.zeros((len(frames), 1024))\n","\n","        # get feature vector from vgg16 for each frame and stack\n","        for index, image in enumerate(frames):\n","            img = cv2.imread(NEGATIVES_PATH + image)\n","            vect = feat_extractor.predict(img.reshape(1,224,224,3))\n","            image_data[index,:] = vect\n","\n","        # for each frame get tensor with lookbacks\n","        stacked_data = np.zeros((len(frames), look_back, 1024))\n","        for index in range(len(frames)):\n","            labels = np.append(labels, [0])\n","            stacked_data[index, 0, :] = image_data[index]\n","            for lb in range(1, look_back):\n","                if index - lb >= 0:\n","                    stacked_data[index, lb, :] = image_data[index - lb]\n","                else:\n","                    stacked_data[index, lb, :] = np.zeros(1024)\n","\n","        if data.shape[0] == 0:\n","            try:\n","              data = stacked_data\n","            except ValueError:\n","              pass\n","        else:\n","            try:\n","              data = np.concatenate([data, stacked_data], axis = 0)\n","            except ValueError:\n","              pass\n","     # one hot labels\n","    from tensorflow.keras.utils import to_categorical\n","    try:\n","      labels = to_categorical(labels)\n","    except ValueError:  #raised if `y` is empty.\n","      pass\n","    return data, labels\n","    \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CT1xBtvOC4Iz"},"source":["tr_data, tr_labels = data_to_lstm_format(POSITIVES_PATH_TRAIN, NEGATIVES_PATH_TRAIN, look_back=LOOK_BACK)\n","val_data, val_labels = data_to_lstm_format(POSITIVES_PATH_VALID, NEGATIVES_PATH_VALID, look_back=LOOK_BACK)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJiMBj3vUA1z"},"source":["from keras.models import Model\n","import keras.layers as L\n","from tensorflow.keras.optimizers import RMSprop\n","\n","num_features = 1024\n","\n","def build_model():\n","    inp = L.Input(shape = (LOOK_BACK, num_features))\n","    \n","    \"\"\" Use CuDNNLSTM if your machine supports CUDA\n","        Training time is significantly faster compared to LSTM \"\"\"\n","    \n","    x = L.LSTM(64, return_sequences = True)(inp)\n","    #x = L.CuDNNLSTM(64, return_sequences = True)(inp)\n","    x = L.Dropout(0.2)(x)\n","    x = L.LSTM(16)(x)\n","    #x = L.CuDNNLSTM(16)(x)\n","    out = L.Dense(2, activation = 'softmax')(x)\n","    model = Model(inputs = [inp], outputs = [out])\n","    model.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['acc'])\n","    return model\n","build_model().summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcY6gzLuUECx"},"source":["from keras.callbacks import TensorBoard\n","##https://www.tensorflow.org/tensorboard/get_started\n","\n","log_dir = \"/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/_training_logs/rnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=0)\n","\n","model = build_model()\n","\n","history = model.fit(tr_data, tr_labels, \n","                    validation_data = (val_data, val_labels),\n","                    callbacks = [tensorboard_callback],\n","                    verbose = 2, epochs = 10, batch_size = 64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oeDIvtLmUGQn"},"source":["# Save the trained model weights to disk\n","model.save('/content/drive/Shareddrives/Part IV Research Project/Medicine Action/weights/RNN.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BF2oSrpdcPYb"},"source":["!pip install tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6SCiGH4R9rVW"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir='/content/drive/Shareddrives/Part IV Research Project/Medicine Action/data/_training_logs/rnn' --host=127.0.0.1"],"execution_count":null,"outputs":[]}]}